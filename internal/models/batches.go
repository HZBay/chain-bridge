// Code generated by SQLBoiler 4.18.0 (https://github.com/volatiletech/sqlboiler). DO NOT EDIT.
// This file is meant to be re-generated in place and/or deleted at any time.

package models

import (
	"context"
	"database/sql"
	"fmt"
	"reflect"
	"strconv"
	"strings"
	"sync"
	"time"

	"github.com/friendsofgo/errors"
	"github.com/volatiletech/null/v8"
	"github.com/volatiletech/sqlboiler/v4/boil"
	"github.com/volatiletech/sqlboiler/v4/queries"
	"github.com/volatiletech/sqlboiler/v4/queries/qm"
	"github.com/volatiletech/sqlboiler/v4/queries/qmhelper"
	"github.com/volatiletech/sqlboiler/v4/types"
	"github.com/volatiletech/strmangle"
)

// Batch is an object representing the database table.
type Batch struct {
	ID                   int               `boil:"id" json:"id" toml:"id" yaml:"id"`
	BatchID              string            `boil:"batch_id" json:"batch_id" toml:"batch_id" yaml:"batch_id"`
	ChainID              int64             `boil:"chain_id" json:"chain_id" toml:"chain_id" yaml:"chain_id"`
	TokenID              int               `boil:"token_id" json:"token_id" toml:"token_id" yaml:"token_id"`
	BatchType            string            `boil:"batch_type" json:"batch_type" toml:"batch_type" yaml:"batch_type"`
	OperationCount       int               `boil:"operation_count" json:"operation_count" toml:"operation_count" yaml:"operation_count"`
	OptimalBatchSize     int               `boil:"optimal_batch_size" json:"optimal_batch_size" toml:"optimal_batch_size" yaml:"optimal_batch_size"`
	ActualEfficiency     types.NullDecimal `boil:"actual_efficiency" json:"actual_efficiency,omitempty" toml:"actual_efficiency" yaml:"actual_efficiency,omitempty"`
	BatchStrategy        null.String       `boil:"batch_strategy" json:"batch_strategy,omitempty" toml:"batch_strategy" yaml:"batch_strategy,omitempty"`
	NetworkCondition     null.String       `boil:"network_condition" json:"network_condition,omitempty" toml:"network_condition" yaml:"network_condition,omitempty"`
	ActualGasUsed        null.Int64        `boil:"actual_gas_used" json:"actual_gas_used,omitempty" toml:"actual_gas_used" yaml:"actual_gas_used,omitempty"`
	GasSaved             null.Int64        `boil:"gas_saved" json:"gas_saved,omitempty" toml:"gas_saved" yaml:"gas_saved,omitempty"`
	GasSavedPercentage   types.NullDecimal `boil:"gas_saved_percentage" json:"gas_saved_percentage,omitempty" toml:"gas_saved_percentage" yaml:"gas_saved_percentage,omitempty"`
	GasSavedUsd          types.NullDecimal `boil:"gas_saved_usd" json:"gas_saved_usd,omitempty" toml:"gas_saved_usd" yaml:"gas_saved_usd,omitempty"`
	CpopOperationType    null.String       `boil:"cpop_operation_type" json:"cpop_operation_type,omitempty" toml:"cpop_operation_type" yaml:"cpop_operation_type,omitempty"`
	MasterAggregatorUsed null.Bool         `boil:"master_aggregator_used" json:"master_aggregator_used,omitempty" toml:"master_aggregator_used" yaml:"master_aggregator_used,omitempty"`
	Status               null.String       `boil:"status" json:"status,omitempty" toml:"status" yaml:"status,omitempty"`
	TXHash               null.String       `boil:"tx_hash" json:"tx_hash,omitempty" toml:"tx_hash" yaml:"tx_hash,omitempty"`
	CreatedAt            null.Time         `boil:"created_at" json:"created_at,omitempty" toml:"created_at" yaml:"created_at,omitempty"`
	ConfirmedAt          null.Time         `boil:"confirmed_at" json:"confirmed_at,omitempty" toml:"confirmed_at" yaml:"confirmed_at,omitempty"`

	R *batchR `boil:"-" json:"-" toml:"-" yaml:"-"`
	L batchL  `boil:"-" json:"-" toml:"-" yaml:"-"`
}

var BatchColumns = struct {
	ID                   string
	BatchID              string
	ChainID              string
	TokenID              string
	BatchType            string
	OperationCount       string
	OptimalBatchSize     string
	ActualEfficiency     string
	BatchStrategy        string
	NetworkCondition     string
	ActualGasUsed        string
	GasSaved             string
	GasSavedPercentage   string
	GasSavedUsd          string
	CpopOperationType    string
	MasterAggregatorUsed string
	Status               string
	TXHash               string
	CreatedAt            string
	ConfirmedAt          string
}{
	ID:                   "id",
	BatchID:              "batch_id",
	ChainID:              "chain_id",
	TokenID:              "token_id",
	BatchType:            "batch_type",
	OperationCount:       "operation_count",
	OptimalBatchSize:     "optimal_batch_size",
	ActualEfficiency:     "actual_efficiency",
	BatchStrategy:        "batch_strategy",
	NetworkCondition:     "network_condition",
	ActualGasUsed:        "actual_gas_used",
	GasSaved:             "gas_saved",
	GasSavedPercentage:   "gas_saved_percentage",
	GasSavedUsd:          "gas_saved_usd",
	CpopOperationType:    "cpop_operation_type",
	MasterAggregatorUsed: "master_aggregator_used",
	Status:               "status",
	TXHash:               "tx_hash",
	CreatedAt:            "created_at",
	ConfirmedAt:          "confirmed_at",
}

var BatchTableColumns = struct {
	ID                   string
	BatchID              string
	ChainID              string
	TokenID              string
	BatchType            string
	OperationCount       string
	OptimalBatchSize     string
	ActualEfficiency     string
	BatchStrategy        string
	NetworkCondition     string
	ActualGasUsed        string
	GasSaved             string
	GasSavedPercentage   string
	GasSavedUsd          string
	CpopOperationType    string
	MasterAggregatorUsed string
	Status               string
	TXHash               string
	CreatedAt            string
	ConfirmedAt          string
}{
	ID:                   "batches.id",
	BatchID:              "batches.batch_id",
	ChainID:              "batches.chain_id",
	TokenID:              "batches.token_id",
	BatchType:            "batches.batch_type",
	OperationCount:       "batches.operation_count",
	OptimalBatchSize:     "batches.optimal_batch_size",
	ActualEfficiency:     "batches.actual_efficiency",
	BatchStrategy:        "batches.batch_strategy",
	NetworkCondition:     "batches.network_condition",
	ActualGasUsed:        "batches.actual_gas_used",
	GasSaved:             "batches.gas_saved",
	GasSavedPercentage:   "batches.gas_saved_percentage",
	GasSavedUsd:          "batches.gas_saved_usd",
	CpopOperationType:    "batches.cpop_operation_type",
	MasterAggregatorUsed: "batches.master_aggregator_used",
	Status:               "batches.status",
	TXHash:               "batches.tx_hash",
	CreatedAt:            "batches.created_at",
	ConfirmedAt:          "batches.confirmed_at",
}

// Generated where

type whereHelperint struct{ field string }

func (w whereHelperint) EQ(x int) qm.QueryMod  { return qmhelper.Where(w.field, qmhelper.EQ, x) }
func (w whereHelperint) NEQ(x int) qm.QueryMod { return qmhelper.Where(w.field, qmhelper.NEQ, x) }
func (w whereHelperint) LT(x int) qm.QueryMod  { return qmhelper.Where(w.field, qmhelper.LT, x) }
func (w whereHelperint) LTE(x int) qm.QueryMod { return qmhelper.Where(w.field, qmhelper.LTE, x) }
func (w whereHelperint) GT(x int) qm.QueryMod  { return qmhelper.Where(w.field, qmhelper.GT, x) }
func (w whereHelperint) GTE(x int) qm.QueryMod { return qmhelper.Where(w.field, qmhelper.GTE, x) }
func (w whereHelperint) IN(slice []int) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereIn(fmt.Sprintf("%s IN ?", w.field), values...)
}
func (w whereHelperint) NIN(slice []int) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereNotIn(fmt.Sprintf("%s NOT IN ?", w.field), values...)
}

type whereHelperint64 struct{ field string }

func (w whereHelperint64) EQ(x int64) qm.QueryMod  { return qmhelper.Where(w.field, qmhelper.EQ, x) }
func (w whereHelperint64) NEQ(x int64) qm.QueryMod { return qmhelper.Where(w.field, qmhelper.NEQ, x) }
func (w whereHelperint64) LT(x int64) qm.QueryMod  { return qmhelper.Where(w.field, qmhelper.LT, x) }
func (w whereHelperint64) LTE(x int64) qm.QueryMod { return qmhelper.Where(w.field, qmhelper.LTE, x) }
func (w whereHelperint64) GT(x int64) qm.QueryMod  { return qmhelper.Where(w.field, qmhelper.GT, x) }
func (w whereHelperint64) GTE(x int64) qm.QueryMod { return qmhelper.Where(w.field, qmhelper.GTE, x) }
func (w whereHelperint64) IN(slice []int64) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereIn(fmt.Sprintf("%s IN ?", w.field), values...)
}
func (w whereHelperint64) NIN(slice []int64) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereNotIn(fmt.Sprintf("%s NOT IN ?", w.field), values...)
}

type whereHelpertypes_NullDecimal struct{ field string }

func (w whereHelpertypes_NullDecimal) EQ(x types.NullDecimal) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, false, x)
}
func (w whereHelpertypes_NullDecimal) NEQ(x types.NullDecimal) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, true, x)
}
func (w whereHelpertypes_NullDecimal) LT(x types.NullDecimal) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LT, x)
}
func (w whereHelpertypes_NullDecimal) LTE(x types.NullDecimal) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LTE, x)
}
func (w whereHelpertypes_NullDecimal) GT(x types.NullDecimal) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GT, x)
}
func (w whereHelpertypes_NullDecimal) GTE(x types.NullDecimal) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GTE, x)
}

func (w whereHelpertypes_NullDecimal) IsNull() qm.QueryMod { return qmhelper.WhereIsNull(w.field) }
func (w whereHelpertypes_NullDecimal) IsNotNull() qm.QueryMod {
	return qmhelper.WhereIsNotNull(w.field)
}

type whereHelpernull_String struct{ field string }

func (w whereHelpernull_String) EQ(x null.String) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, false, x)
}
func (w whereHelpernull_String) NEQ(x null.String) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, true, x)
}
func (w whereHelpernull_String) LT(x null.String) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LT, x)
}
func (w whereHelpernull_String) LTE(x null.String) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LTE, x)
}
func (w whereHelpernull_String) GT(x null.String) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GT, x)
}
func (w whereHelpernull_String) GTE(x null.String) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GTE, x)
}
func (w whereHelpernull_String) LIKE(x null.String) qm.QueryMod {
	return qm.Where(w.field+" LIKE ?", x)
}
func (w whereHelpernull_String) NLIKE(x null.String) qm.QueryMod {
	return qm.Where(w.field+" NOT LIKE ?", x)
}
func (w whereHelpernull_String) ILIKE(x null.String) qm.QueryMod {
	return qm.Where(w.field+" ILIKE ?", x)
}
func (w whereHelpernull_String) NILIKE(x null.String) qm.QueryMod {
	return qm.Where(w.field+" NOT ILIKE ?", x)
}
func (w whereHelpernull_String) SIMILAR(x null.String) qm.QueryMod {
	return qm.Where(w.field+" SIMILAR TO ?", x)
}
func (w whereHelpernull_String) NSIMILAR(x null.String) qm.QueryMod {
	return qm.Where(w.field+" NOT SIMILAR TO ?", x)
}
func (w whereHelpernull_String) IN(slice []string) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereIn(fmt.Sprintf("%s IN ?", w.field), values...)
}
func (w whereHelpernull_String) NIN(slice []string) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereNotIn(fmt.Sprintf("%s NOT IN ?", w.field), values...)
}

func (w whereHelpernull_String) IsNull() qm.QueryMod    { return qmhelper.WhereIsNull(w.field) }
func (w whereHelpernull_String) IsNotNull() qm.QueryMod { return qmhelper.WhereIsNotNull(w.field) }

type whereHelpernull_Int64 struct{ field string }

func (w whereHelpernull_Int64) EQ(x null.Int64) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, false, x)
}
func (w whereHelpernull_Int64) NEQ(x null.Int64) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, true, x)
}
func (w whereHelpernull_Int64) LT(x null.Int64) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LT, x)
}
func (w whereHelpernull_Int64) LTE(x null.Int64) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LTE, x)
}
func (w whereHelpernull_Int64) GT(x null.Int64) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GT, x)
}
func (w whereHelpernull_Int64) GTE(x null.Int64) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GTE, x)
}
func (w whereHelpernull_Int64) IN(slice []int64) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereIn(fmt.Sprintf("%s IN ?", w.field), values...)
}
func (w whereHelpernull_Int64) NIN(slice []int64) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereNotIn(fmt.Sprintf("%s NOT IN ?", w.field), values...)
}

func (w whereHelpernull_Int64) IsNull() qm.QueryMod    { return qmhelper.WhereIsNull(w.field) }
func (w whereHelpernull_Int64) IsNotNull() qm.QueryMod { return qmhelper.WhereIsNotNull(w.field) }

type whereHelpernull_Bool struct{ field string }

func (w whereHelpernull_Bool) EQ(x null.Bool) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, false, x)
}
func (w whereHelpernull_Bool) NEQ(x null.Bool) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, true, x)
}
func (w whereHelpernull_Bool) LT(x null.Bool) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LT, x)
}
func (w whereHelpernull_Bool) LTE(x null.Bool) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LTE, x)
}
func (w whereHelpernull_Bool) GT(x null.Bool) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GT, x)
}
func (w whereHelpernull_Bool) GTE(x null.Bool) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GTE, x)
}

func (w whereHelpernull_Bool) IsNull() qm.QueryMod    { return qmhelper.WhereIsNull(w.field) }
func (w whereHelpernull_Bool) IsNotNull() qm.QueryMod { return qmhelper.WhereIsNotNull(w.field) }

var BatchWhere = struct {
	ID                   whereHelperint
	BatchID              whereHelperstring
	ChainID              whereHelperint64
	TokenID              whereHelperint
	BatchType            whereHelperstring
	OperationCount       whereHelperint
	OptimalBatchSize     whereHelperint
	ActualEfficiency     whereHelpertypes_NullDecimal
	BatchStrategy        whereHelpernull_String
	NetworkCondition     whereHelpernull_String
	ActualGasUsed        whereHelpernull_Int64
	GasSaved             whereHelpernull_Int64
	GasSavedPercentage   whereHelpertypes_NullDecimal
	GasSavedUsd          whereHelpertypes_NullDecimal
	CpopOperationType    whereHelpernull_String
	MasterAggregatorUsed whereHelpernull_Bool
	Status               whereHelpernull_String
	TXHash               whereHelpernull_String
	CreatedAt            whereHelpernull_Time
	ConfirmedAt          whereHelpernull_Time
}{
	ID:                   whereHelperint{field: "\"batches\".\"id\""},
	BatchID:              whereHelperstring{field: "\"batches\".\"batch_id\""},
	ChainID:              whereHelperint64{field: "\"batches\".\"chain_id\""},
	TokenID:              whereHelperint{field: "\"batches\".\"token_id\""},
	BatchType:            whereHelperstring{field: "\"batches\".\"batch_type\""},
	OperationCount:       whereHelperint{field: "\"batches\".\"operation_count\""},
	OptimalBatchSize:     whereHelperint{field: "\"batches\".\"optimal_batch_size\""},
	ActualEfficiency:     whereHelpertypes_NullDecimal{field: "\"batches\".\"actual_efficiency\""},
	BatchStrategy:        whereHelpernull_String{field: "\"batches\".\"batch_strategy\""},
	NetworkCondition:     whereHelpernull_String{field: "\"batches\".\"network_condition\""},
	ActualGasUsed:        whereHelpernull_Int64{field: "\"batches\".\"actual_gas_used\""},
	GasSaved:             whereHelpernull_Int64{field: "\"batches\".\"gas_saved\""},
	GasSavedPercentage:   whereHelpertypes_NullDecimal{field: "\"batches\".\"gas_saved_percentage\""},
	GasSavedUsd:          whereHelpertypes_NullDecimal{field: "\"batches\".\"gas_saved_usd\""},
	CpopOperationType:    whereHelpernull_String{field: "\"batches\".\"cpop_operation_type\""},
	MasterAggregatorUsed: whereHelpernull_Bool{field: "\"batches\".\"master_aggregator_used\""},
	Status:               whereHelpernull_String{field: "\"batches\".\"status\""},
	TXHash:               whereHelpernull_String{field: "\"batches\".\"tx_hash\""},
	CreatedAt:            whereHelpernull_Time{field: "\"batches\".\"created_at\""},
	ConfirmedAt:          whereHelpernull_Time{field: "\"batches\".\"confirmed_at\""},
}

// BatchRels is where relationship names are stored.
var BatchRels = struct {
	Chain string
	Token string
}{
	Chain: "Chain",
	Token: "Token",
}

// batchR is where relationships are stored.
type batchR struct {
	Chain *Chain          `boil:"Chain" json:"Chain" toml:"Chain" yaml:"Chain"`
	Token *SupportedToken `boil:"Token" json:"Token" toml:"Token" yaml:"Token"`
}

// NewStruct creates a new relationship struct
func (*batchR) NewStruct() *batchR {
	return &batchR{}
}

func (r *batchR) GetChain() *Chain {
	if r == nil {
		return nil
	}
	return r.Chain
}

func (r *batchR) GetToken() *SupportedToken {
	if r == nil {
		return nil
	}
	return r.Token
}

// batchL is where Load methods for each relationship are stored.
type batchL struct{}

var (
	batchAllColumns            = []string{"id", "batch_id", "chain_id", "token_id", "batch_type", "operation_count", "optimal_batch_size", "actual_efficiency", "batch_strategy", "network_condition", "actual_gas_used", "gas_saved", "gas_saved_percentage", "gas_saved_usd", "cpop_operation_type", "master_aggregator_used", "status", "tx_hash", "created_at", "confirmed_at"}
	batchColumnsWithoutDefault = []string{"batch_id", "chain_id", "token_id", "batch_type", "operation_count", "optimal_batch_size"}
	batchColumnsWithDefault    = []string{"id", "actual_efficiency", "batch_strategy", "network_condition", "actual_gas_used", "gas_saved", "gas_saved_percentage", "gas_saved_usd", "cpop_operation_type", "master_aggregator_used", "status", "tx_hash", "created_at", "confirmed_at"}
	batchPrimaryKeyColumns     = []string{"id"}
	batchGeneratedColumns      = []string{}
)

type (
	// BatchSlice is an alias for a slice of pointers to Batch.
	// This should almost always be used instead of []Batch.
	BatchSlice []*Batch

	batchQuery struct {
		*queries.Query
	}
)

// Cache for insert, update and upsert
var (
	batchType                 = reflect.TypeOf(&Batch{})
	batchMapping              = queries.MakeStructMapping(batchType)
	batchPrimaryKeyMapping, _ = queries.BindMapping(batchType, batchMapping, batchPrimaryKeyColumns)
	batchInsertCacheMut       sync.RWMutex
	batchInsertCache          = make(map[string]insertCache)
	batchUpdateCacheMut       sync.RWMutex
	batchUpdateCache          = make(map[string]updateCache)
	batchUpsertCacheMut       sync.RWMutex
	batchUpsertCache          = make(map[string]insertCache)
)

var (
	// Force time package dependency for automated UpdatedAt/CreatedAt.
	_ = time.Second
	// Force qmhelper dependency for where clause generation (which doesn't
	// always happen)
	_ = qmhelper.Where
)

// One returns a single batch record from the query.
func (q batchQuery) One(ctx context.Context, exec boil.ContextExecutor) (*Batch, error) {
	o := &Batch{}

	queries.SetLimit(q.Query, 1)

	err := q.Bind(ctx, exec, o)
	if err != nil {
		if errors.Is(err, sql.ErrNoRows) {
			return nil, sql.ErrNoRows
		}
		return nil, errors.Wrap(err, "models: failed to execute a one query for batches")
	}

	return o, nil
}

// All returns all Batch records from the query.
func (q batchQuery) All(ctx context.Context, exec boil.ContextExecutor) (BatchSlice, error) {
	var o []*Batch

	err := q.Bind(ctx, exec, &o)
	if err != nil {
		return nil, errors.Wrap(err, "models: failed to assign all query results to Batch slice")
	}

	return o, nil
}

// Count returns the count of all Batch records in the query.
func (q batchQuery) Count(ctx context.Context, exec boil.ContextExecutor) (int64, error) {
	var count int64

	queries.SetSelect(q.Query, nil)
	queries.SetCount(q.Query)

	err := q.Query.QueryRowContext(ctx, exec).Scan(&count)
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to count batches rows")
	}

	return count, nil
}

// Exists checks if the row exists in the table.
func (q batchQuery) Exists(ctx context.Context, exec boil.ContextExecutor) (bool, error) {
	var count int64

	queries.SetSelect(q.Query, nil)
	queries.SetCount(q.Query)
	queries.SetLimit(q.Query, 1)

	err := q.Query.QueryRowContext(ctx, exec).Scan(&count)
	if err != nil {
		return false, errors.Wrap(err, "models: failed to check if batches exists")
	}

	return count > 0, nil
}

// Chain pointed to by the foreign key.
func (o *Batch) Chain(mods ...qm.QueryMod) chainQuery {
	queryMods := []qm.QueryMod{
		qm.Where("\"chain_id\" = ?", o.ChainID),
	}

	queryMods = append(queryMods, mods...)

	return Chains(queryMods...)
}

// Token pointed to by the foreign key.
func (o *Batch) Token(mods ...qm.QueryMod) supportedTokenQuery {
	queryMods := []qm.QueryMod{
		qm.Where("\"id\" = ?", o.TokenID),
	}

	queryMods = append(queryMods, mods...)

	return SupportedTokens(queryMods...)
}

// LoadChain allows an eager lookup of values, cached into the
// loaded structs of the objects. This is for an N-1 relationship.
func (batchL) LoadChain(ctx context.Context, e boil.ContextExecutor, singular bool, maybeBatch interface{}, mods queries.Applicator) error {
	var slice []*Batch
	var object *Batch

	if singular {
		var ok bool
		object, ok = maybeBatch.(*Batch)
		if !ok {
			object = new(Batch)
			ok = queries.SetFromEmbeddedStruct(&object, &maybeBatch)
			if !ok {
				return errors.New(fmt.Sprintf("failed to set %T from embedded struct %T", object, maybeBatch))
			}
		}
	} else {
		s, ok := maybeBatch.(*[]*Batch)
		if ok {
			slice = *s
		} else {
			ok = queries.SetFromEmbeddedStruct(&slice, maybeBatch)
			if !ok {
				return errors.New(fmt.Sprintf("failed to set %T from embedded struct %T", slice, maybeBatch))
			}
		}
	}

	args := make(map[interface{}]struct{})
	if singular {
		if object.R == nil {
			object.R = &batchR{}
		}
		args[object.ChainID] = struct{}{}

	} else {
		for _, obj := range slice {
			if obj.R == nil {
				obj.R = &batchR{}
			}

			args[obj.ChainID] = struct{}{}

		}
	}

	if len(args) == 0 {
		return nil
	}

	argsSlice := make([]interface{}, len(args))
	i := 0
	for arg := range args {
		argsSlice[i] = arg
		i++
	}

	query := NewQuery(
		qm.From(`chains`),
		qm.WhereIn(`chains.chain_id in ?`, argsSlice...),
	)
	if mods != nil {
		mods.Apply(query)
	}

	results, err := query.QueryContext(ctx, e)
	if err != nil {
		return errors.Wrap(err, "failed to eager load Chain")
	}

	var resultSlice []*Chain
	if err = queries.Bind(results, &resultSlice); err != nil {
		return errors.Wrap(err, "failed to bind eager loaded slice Chain")
	}

	if err = results.Close(); err != nil {
		return errors.Wrap(err, "failed to close results of eager load for chains")
	}
	if err = results.Err(); err != nil {
		return errors.Wrap(err, "error occurred during iteration of eager loaded relations for chains")
	}

	if len(resultSlice) == 0 {
		return nil
	}

	if singular {
		foreign := resultSlice[0]
		object.R.Chain = foreign
		if foreign.R == nil {
			foreign.R = &chainR{}
		}
		foreign.R.Batches = append(foreign.R.Batches, object)
		return nil
	}

	for _, local := range slice {
		for _, foreign := range resultSlice {
			if local.ChainID == foreign.ChainID {
				local.R.Chain = foreign
				if foreign.R == nil {
					foreign.R = &chainR{}
				}
				foreign.R.Batches = append(foreign.R.Batches, local)
				break
			}
		}
	}

	return nil
}

// LoadToken allows an eager lookup of values, cached into the
// loaded structs of the objects. This is for an N-1 relationship.
func (batchL) LoadToken(ctx context.Context, e boil.ContextExecutor, singular bool, maybeBatch interface{}, mods queries.Applicator) error {
	var slice []*Batch
	var object *Batch

	if singular {
		var ok bool
		object, ok = maybeBatch.(*Batch)
		if !ok {
			object = new(Batch)
			ok = queries.SetFromEmbeddedStruct(&object, &maybeBatch)
			if !ok {
				return errors.New(fmt.Sprintf("failed to set %T from embedded struct %T", object, maybeBatch))
			}
		}
	} else {
		s, ok := maybeBatch.(*[]*Batch)
		if ok {
			slice = *s
		} else {
			ok = queries.SetFromEmbeddedStruct(&slice, maybeBatch)
			if !ok {
				return errors.New(fmt.Sprintf("failed to set %T from embedded struct %T", slice, maybeBatch))
			}
		}
	}

	args := make(map[interface{}]struct{})
	if singular {
		if object.R == nil {
			object.R = &batchR{}
		}
		args[object.TokenID] = struct{}{}

	} else {
		for _, obj := range slice {
			if obj.R == nil {
				obj.R = &batchR{}
			}

			args[obj.TokenID] = struct{}{}

		}
	}

	if len(args) == 0 {
		return nil
	}

	argsSlice := make([]interface{}, len(args))
	i := 0
	for arg := range args {
		argsSlice[i] = arg
		i++
	}

	query := NewQuery(
		qm.From(`supported_tokens`),
		qm.WhereIn(`supported_tokens.id in ?`, argsSlice...),
	)
	if mods != nil {
		mods.Apply(query)
	}

	results, err := query.QueryContext(ctx, e)
	if err != nil {
		return errors.Wrap(err, "failed to eager load SupportedToken")
	}

	var resultSlice []*SupportedToken
	if err = queries.Bind(results, &resultSlice); err != nil {
		return errors.Wrap(err, "failed to bind eager loaded slice SupportedToken")
	}

	if err = results.Close(); err != nil {
		return errors.Wrap(err, "failed to close results of eager load for supported_tokens")
	}
	if err = results.Err(); err != nil {
		return errors.Wrap(err, "error occurred during iteration of eager loaded relations for supported_tokens")
	}

	if len(resultSlice) == 0 {
		return nil
	}

	if singular {
		foreign := resultSlice[0]
		object.R.Token = foreign
		if foreign.R == nil {
			foreign.R = &supportedTokenR{}
		}
		foreign.R.TokenBatches = append(foreign.R.TokenBatches, object)
		return nil
	}

	for _, local := range slice {
		for _, foreign := range resultSlice {
			if local.TokenID == foreign.ID {
				local.R.Token = foreign
				if foreign.R == nil {
					foreign.R = &supportedTokenR{}
				}
				foreign.R.TokenBatches = append(foreign.R.TokenBatches, local)
				break
			}
		}
	}

	return nil
}

// SetChain of the batch to the related item.
// Sets o.R.Chain to related.
// Adds o to related.R.Batches.
func (o *Batch) SetChain(ctx context.Context, exec boil.ContextExecutor, insert bool, related *Chain) error {
	var err error
	if insert {
		if err = related.Insert(ctx, exec, boil.Infer()); err != nil {
			return errors.Wrap(err, "failed to insert into foreign table")
		}
	}

	updateQuery := fmt.Sprintf(
		"UPDATE \"batches\" SET %s WHERE %s",
		strmangle.SetParamNames("\"", "\"", 1, []string{"chain_id"}),
		strmangle.WhereClause("\"", "\"", 2, batchPrimaryKeyColumns),
	)
	values := []interface{}{related.ChainID, o.ID}

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, updateQuery)
		fmt.Fprintln(writer, values)
	}
	if _, err = exec.ExecContext(ctx, updateQuery, values...); err != nil {
		return errors.Wrap(err, "failed to update local table")
	}

	o.ChainID = related.ChainID
	if o.R == nil {
		o.R = &batchR{
			Chain: related,
		}
	} else {
		o.R.Chain = related
	}

	if related.R == nil {
		related.R = &chainR{
			Batches: BatchSlice{o},
		}
	} else {
		related.R.Batches = append(related.R.Batches, o)
	}

	return nil
}

// SetToken of the batch to the related item.
// Sets o.R.Token to related.
// Adds o to related.R.TokenBatches.
func (o *Batch) SetToken(ctx context.Context, exec boil.ContextExecutor, insert bool, related *SupportedToken) error {
	var err error
	if insert {
		if err = related.Insert(ctx, exec, boil.Infer()); err != nil {
			return errors.Wrap(err, "failed to insert into foreign table")
		}
	}

	updateQuery := fmt.Sprintf(
		"UPDATE \"batches\" SET %s WHERE %s",
		strmangle.SetParamNames("\"", "\"", 1, []string{"token_id"}),
		strmangle.WhereClause("\"", "\"", 2, batchPrimaryKeyColumns),
	)
	values := []interface{}{related.ID, o.ID}

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, updateQuery)
		fmt.Fprintln(writer, values)
	}
	if _, err = exec.ExecContext(ctx, updateQuery, values...); err != nil {
		return errors.Wrap(err, "failed to update local table")
	}

	o.TokenID = related.ID
	if o.R == nil {
		o.R = &batchR{
			Token: related,
		}
	} else {
		o.R.Token = related
	}

	if related.R == nil {
		related.R = &supportedTokenR{
			TokenBatches: BatchSlice{o},
		}
	} else {
		related.R.TokenBatches = append(related.R.TokenBatches, o)
	}

	return nil
}

// Batches retrieves all the records using an executor.
func Batches(mods ...qm.QueryMod) batchQuery {
	mods = append(mods, qm.From("\"batches\""))
	q := NewQuery(mods...)
	if len(queries.GetSelect(q)) == 0 {
		queries.SetSelect(q, []string{"\"batches\".*"})
	}

	return batchQuery{q}
}

// FindBatch retrieves a single record by ID with an executor.
// If selectCols is empty Find will return all columns.
func FindBatch(ctx context.Context, exec boil.ContextExecutor, iD int, selectCols ...string) (*Batch, error) {
	batchObj := &Batch{}

	sel := "*"
	if len(selectCols) > 0 {
		sel = strings.Join(strmangle.IdentQuoteSlice(dialect.LQ, dialect.RQ, selectCols), ",")
	}
	query := fmt.Sprintf(
		"select %s from \"batches\" where \"id\"=$1", sel,
	)

	q := queries.Raw(query, iD)

	err := q.Bind(ctx, exec, batchObj)
	if err != nil {
		if errors.Is(err, sql.ErrNoRows) {
			return nil, sql.ErrNoRows
		}
		return nil, errors.Wrap(err, "models: unable to select from batches")
	}

	return batchObj, nil
}

// Insert a single record using an executor.
// See boil.Columns.InsertColumnSet documentation to understand column list inference for inserts.
func (o *Batch) Insert(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns) error {
	if o == nil {
		return errors.New("models: no batches provided for insertion")
	}

	var err error
	if !boil.TimestampsAreSkipped(ctx) {
		currTime := time.Now().In(boil.GetLocation())

		if queries.MustTime(o.CreatedAt).IsZero() {
			queries.SetScanner(&o.CreatedAt, currTime)
		}
	}

	nzDefaults := queries.NonZeroDefaultSet(batchColumnsWithDefault, o)

	key := makeCacheKey(columns, nzDefaults)
	batchInsertCacheMut.RLock()
	cache, cached := batchInsertCache[key]
	batchInsertCacheMut.RUnlock()

	if !cached {
		wl, returnColumns := columns.InsertColumnSet(
			batchAllColumns,
			batchColumnsWithDefault,
			batchColumnsWithoutDefault,
			nzDefaults,
		)

		cache.valueMapping, err = queries.BindMapping(batchType, batchMapping, wl)
		if err != nil {
			return err
		}
		cache.retMapping, err = queries.BindMapping(batchType, batchMapping, returnColumns)
		if err != nil {
			return err
		}
		if len(wl) != 0 {
			cache.query = fmt.Sprintf("INSERT INTO \"batches\" (\"%s\") %%sVALUES (%s)%%s", strings.Join(wl, "\",\""), strmangle.Placeholders(dialect.UseIndexPlaceholders, len(wl), 1, 1))
		} else {
			cache.query = "INSERT INTO \"batches\" %sDEFAULT VALUES%s"
		}

		var queryOutput, queryReturning string

		if len(cache.retMapping) != 0 {
			queryReturning = fmt.Sprintf(" RETURNING \"%s\"", strings.Join(returnColumns, "\",\""))
		}

		cache.query = fmt.Sprintf(cache.query, queryOutput, queryReturning)
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	vals := queries.ValuesFromMapping(value, cache.valueMapping)

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.query)
		fmt.Fprintln(writer, vals)
	}

	if len(cache.retMapping) != 0 {
		err = exec.QueryRowContext(ctx, cache.query, vals...).Scan(queries.PtrsFromMapping(value, cache.retMapping)...)
	} else {
		_, err = exec.ExecContext(ctx, cache.query, vals...)
	}

	if err != nil {
		return errors.Wrap(err, "models: unable to insert into batches")
	}

	if !cached {
		batchInsertCacheMut.Lock()
		batchInsertCache[key] = cache
		batchInsertCacheMut.Unlock()
	}

	return nil
}

// Update uses an executor to update the Batch.
// See boil.Columns.UpdateColumnSet documentation to understand column list inference for updates.
// Update does not automatically update the record in case of default values. Use .Reload() to refresh the records.
func (o *Batch) Update(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns) (int64, error) {
	var err error
	key := makeCacheKey(columns, nil)
	batchUpdateCacheMut.RLock()
	cache, cached := batchUpdateCache[key]
	batchUpdateCacheMut.RUnlock()

	if !cached {
		wl := columns.UpdateColumnSet(
			batchAllColumns,
			batchPrimaryKeyColumns,
		)

		if !columns.IsWhitelist() {
			wl = strmangle.SetComplement(wl, []string{"created_at"})
		}
		if len(wl) == 0 {
			return 0, errors.New("models: unable to update batches, could not build whitelist")
		}

		cache.query = fmt.Sprintf("UPDATE \"batches\" SET %s WHERE %s",
			strmangle.SetParamNames("\"", "\"", 1, wl),
			strmangle.WhereClause("\"", "\"", len(wl)+1, batchPrimaryKeyColumns),
		)
		cache.valueMapping, err = queries.BindMapping(batchType, batchMapping, append(wl, batchPrimaryKeyColumns...))
		if err != nil {
			return 0, err
		}
	}

	values := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), cache.valueMapping)

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.query)
		fmt.Fprintln(writer, values)
	}
	var result sql.Result
	result, err = exec.ExecContext(ctx, cache.query, values...)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to update batches row")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to get rows affected by update for batches")
	}

	if !cached {
		batchUpdateCacheMut.Lock()
		batchUpdateCache[key] = cache
		batchUpdateCacheMut.Unlock()
	}

	return rowsAff, nil
}

// UpdateAll updates all rows with the specified column values.
func (q batchQuery) UpdateAll(ctx context.Context, exec boil.ContextExecutor, cols M) (int64, error) {
	queries.SetUpdate(q.Query, cols)

	result, err := q.Query.ExecContext(ctx, exec)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to update all for batches")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to retrieve rows affected for batches")
	}

	return rowsAff, nil
}

// UpdateAll updates all rows with the specified column values, using an executor.
func (o BatchSlice) UpdateAll(ctx context.Context, exec boil.ContextExecutor, cols M) (int64, error) {
	ln := int64(len(o))
	if ln == 0 {
		return 0, nil
	}

	if len(cols) == 0 {
		return 0, errors.New("models: update all requires at least one column argument")
	}

	colNames := make([]string, len(cols))
	args := make([]interface{}, len(cols))

	i := 0
	for name, value := range cols {
		colNames[i] = name
		args[i] = value
		i++
	}

	// Append all of the primary key values for each column
	for _, obj := range o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), batchPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := fmt.Sprintf("UPDATE \"batches\" SET %s WHERE %s",
		strmangle.SetParamNames("\"", "\"", 1, colNames),
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), len(colNames)+1, batchPrimaryKeyColumns, len(o)))

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, args...)
	}
	result, err := exec.ExecContext(ctx, sql, args...)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to update all in batch slice")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to retrieve rows affected all in update all batch")
	}
	return rowsAff, nil
}

// Upsert attempts an insert using an executor, and does an update or ignore on conflict.
// See boil.Columns documentation for how to properly use updateColumns and insertColumns.
func (o *Batch) Upsert(ctx context.Context, exec boil.ContextExecutor, updateOnConflict bool, conflictColumns []string, updateColumns, insertColumns boil.Columns, opts ...UpsertOptionFunc) error {
	if o == nil {
		return errors.New("models: no batches provided for upsert")
	}
	if !boil.TimestampsAreSkipped(ctx) {
		currTime := time.Now().In(boil.GetLocation())

		if queries.MustTime(o.CreatedAt).IsZero() {
			queries.SetScanner(&o.CreatedAt, currTime)
		}
	}

	nzDefaults := queries.NonZeroDefaultSet(batchColumnsWithDefault, o)

	// Build cache key in-line uglily - mysql vs psql problems
	buf := strmangle.GetBuffer()
	if updateOnConflict {
		buf.WriteByte('t')
	} else {
		buf.WriteByte('f')
	}
	buf.WriteByte('.')
	for _, c := range conflictColumns {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	buf.WriteString(strconv.Itoa(updateColumns.Kind))
	for _, c := range updateColumns.Cols {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	buf.WriteString(strconv.Itoa(insertColumns.Kind))
	for _, c := range insertColumns.Cols {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	for _, c := range nzDefaults {
		buf.WriteString(c)
	}
	key := buf.String()
	strmangle.PutBuffer(buf)

	batchUpsertCacheMut.RLock()
	cache, cached := batchUpsertCache[key]
	batchUpsertCacheMut.RUnlock()

	var err error

	if !cached {
		insert, _ := insertColumns.InsertColumnSet(
			batchAllColumns,
			batchColumnsWithDefault,
			batchColumnsWithoutDefault,
			nzDefaults,
		)

		update := updateColumns.UpdateColumnSet(
			batchAllColumns,
			batchPrimaryKeyColumns,
		)

		if updateOnConflict && len(update) == 0 {
			return errors.New("models: unable to upsert batches, could not build update column list")
		}

		ret := strmangle.SetComplement(batchAllColumns, strmangle.SetIntersect(insert, update))

		conflict := conflictColumns
		if len(conflict) == 0 && updateOnConflict && len(update) != 0 {
			if len(batchPrimaryKeyColumns) == 0 {
				return errors.New("models: unable to upsert batches, could not build conflict column list")
			}

			conflict = make([]string, len(batchPrimaryKeyColumns))
			copy(conflict, batchPrimaryKeyColumns)
		}
		cache.query = buildUpsertQueryPostgres(dialect, "\"batches\"", updateOnConflict, ret, update, conflict, insert, opts...)

		cache.valueMapping, err = queries.BindMapping(batchType, batchMapping, insert)
		if err != nil {
			return err
		}
		if len(ret) != 0 {
			cache.retMapping, err = queries.BindMapping(batchType, batchMapping, ret)
			if err != nil {
				return err
			}
		}
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	vals := queries.ValuesFromMapping(value, cache.valueMapping)
	var returns []interface{}
	if len(cache.retMapping) != 0 {
		returns = queries.PtrsFromMapping(value, cache.retMapping)
	}

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.query)
		fmt.Fprintln(writer, vals)
	}
	if len(cache.retMapping) != 0 {
		err = exec.QueryRowContext(ctx, cache.query, vals...).Scan(returns...)
		if errors.Is(err, sql.ErrNoRows) {
			err = nil // Postgres doesn't return anything when there's no update
		}
	} else {
		_, err = exec.ExecContext(ctx, cache.query, vals...)
	}
	if err != nil {
		return errors.Wrap(err, "models: unable to upsert batches")
	}

	if !cached {
		batchUpsertCacheMut.Lock()
		batchUpsertCache[key] = cache
		batchUpsertCacheMut.Unlock()
	}

	return nil
}

// Delete deletes a single Batch record with an executor.
// Delete will match against the primary key column to find the record to delete.
func (o *Batch) Delete(ctx context.Context, exec boil.ContextExecutor) (int64, error) {
	if o == nil {
		return 0, errors.New("models: no Batch provided for delete")
	}

	args := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), batchPrimaryKeyMapping)
	sql := "DELETE FROM \"batches\" WHERE \"id\"=$1"

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, args...)
	}
	result, err := exec.ExecContext(ctx, sql, args...)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to delete from batches")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to get rows affected by delete for batches")
	}

	return rowsAff, nil
}

// DeleteAll deletes all matching rows.
func (q batchQuery) DeleteAll(ctx context.Context, exec boil.ContextExecutor) (int64, error) {
	if q.Query == nil {
		return 0, errors.New("models: no batchQuery provided for delete all")
	}

	queries.SetDelete(q.Query)

	result, err := q.Query.ExecContext(ctx, exec)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to delete all from batches")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to get rows affected by deleteall for batches")
	}

	return rowsAff, nil
}

// DeleteAll deletes all rows in the slice, using an executor.
func (o BatchSlice) DeleteAll(ctx context.Context, exec boil.ContextExecutor) (int64, error) {
	if len(o) == 0 {
		return 0, nil
	}

	var args []interface{}
	for _, obj := range o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), batchPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := "DELETE FROM \"batches\" WHERE " +
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 1, batchPrimaryKeyColumns, len(o))

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, args)
	}
	result, err := exec.ExecContext(ctx, sql, args...)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to delete all from batch slice")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to get rows affected by deleteall for batches")
	}

	return rowsAff, nil
}

// Reload refetches the object from the database
// using the primary keys with an executor.
func (o *Batch) Reload(ctx context.Context, exec boil.ContextExecutor) error {
	ret, err := FindBatch(ctx, exec, o.ID)
	if err != nil {
		return err
	}

	*o = *ret
	return nil
}

// ReloadAll refetches every row with matching primary key column values
// and overwrites the original object slice with the newly updated slice.
func (o *BatchSlice) ReloadAll(ctx context.Context, exec boil.ContextExecutor) error {
	if o == nil || len(*o) == 0 {
		return nil
	}

	slice := BatchSlice{}
	var args []interface{}
	for _, obj := range *o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), batchPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := "SELECT \"batches\".* FROM \"batches\" WHERE " +
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 1, batchPrimaryKeyColumns, len(*o))

	q := queries.Raw(sql, args...)

	err := q.Bind(ctx, exec, &slice)
	if err != nil {
		return errors.Wrap(err, "models: unable to reload all in BatchSlice")
	}

	*o = slice

	return nil
}

// BatchExists checks if the Batch row exists.
func BatchExists(ctx context.Context, exec boil.ContextExecutor, iD int) (bool, error) {
	var exists bool
	sql := "select exists(select 1 from \"batches\" where \"id\"=$1 limit 1)"

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, iD)
	}
	row := exec.QueryRowContext(ctx, sql, iD)

	err := row.Scan(&exists)
	if err != nil {
		return false, errors.Wrap(err, "models: unable to check if batches exists")
	}

	return exists, nil
}

// Exists checks if the Batch row exists.
func (o *Batch) Exists(ctx context.Context, exec boil.ContextExecutor) (bool, error) {
	return BatchExists(ctx, exec, o.ID)
}
